<!doctype html><html lang=en-uk><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.146.5"><title>CONDOR | Marco Bacis</title>
<meta name=description content="CONDOR (Convolutional neural network Dataflow Optimization using Reconfigurable hardware) is a project started in Novmber 2016 and that I left in May 2018, which aims at creating a scalable and easy-to-use framework to accelerate convolutional neural networks using FPGAs in the cloud.
Abstract
From the last published paper (May 2018):
&ldquo;The recent years have seen a rapid diffusion of deep learning algorithms as Convolutional Neural Networks, and as a consequence, an intensification of industrial and academic research focused on optimizing their implementation.
Different computing architectures have been explored, and among all of them, FPGAs seem to be a very attractive choice, since they can deliver sustained performance with high power efficiency, as CNNs can be directly mapped onto hardware, and still offer flexibility thanks to their programmability."><meta name=twitter:card content="summary"><meta name=twitter:title content="CONDOR"><meta name=twitter:description content="CONDOR (Convolutional neural network Dataflow Optimization using Reconfigurable hardware) is a project started in Novmber 2016 and that I left in May 2018, which aims at creating a scalable and easy-to-use framework to accelerate convolutional neural networks using FPGAs in the cloud.
Abstract From the last published paper (May 2018):
“The recent years have seen a rapid diffusion of deep learning algorithms as Convolutional Neural Networks, and as a consequence, an intensification of industrial and academic research focused on optimizing their implementation. Different computing architectures have been explored, and among all of them, FPGAs seem to be a very attractive choice, since they can deliver sustained performance with high power efficiency, as CNNs can be directly mapped onto hardware, and still offer flexibility thanks to their programmability."><meta property="og:url" content="https://marcobacis.com/static/projects/condor/"><meta property="og:site_name" content="Marco Bacis"><meta property="og:title" content="CONDOR"><meta property="og:description" content="CONDOR (Convolutional neural network Dataflow Optimization using Reconfigurable hardware) is a project started in Novmber 2016 and that I left in May 2018, which aims at creating a scalable and easy-to-use framework to accelerate convolutional neural networks using FPGAs in the cloud.
Abstract From the last published paper (May 2018):
“The recent years have seen a rapid diffusion of deep learning algorithms as Convolutional Neural Networks, and as a consequence, an intensification of industrial and academic research focused on optimizing their implementation. Different computing architectures have been explored, and among all of them, FPGAs seem to be a very attractive choice, since they can deliver sustained performance with high power efficiency, as CNNs can be directly mapped onto hardware, and still offer flexibility thanks to their programmability."><meta property="og:locale" content="en_uk"><meta property="og:type" content="article"><meta property="article:section" content="static"><meta property="article:modified_time" content="2025-04-18T01:26:50+00:00"><link href=https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css rel=stylesheet integrity=sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T crossorigin=anonymous><script src=https://kit.fontawesome.com/06d3e22684.js crossorigin=anonymous></script><link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel=stylesheet><link href=/css/medium.css rel=stylesheet><link href=/css/additional.css rel=stylesheet><script defer src=https://umami.marcobacis.com/script.js data-website-id=435d89b9-0e4c-4831-9214-edf318b03138></script><link rel=alternate type=application/rss+xml href=https://marcobacis.com/blog/index.xml title="Marco Bacis Blog"></head><body><nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down"><div class="container pr-0"><a class=navbar-brand href=https://marcobacis.com//><span style=font-family:Righteous>Marco Bacis</span>
</a><button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarMediumish aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarMediumish><ul class="navbar-nav ml-auto"><li class=nav-item><a class=nav-link href=/>Home</a></li><li class=nav-item><a class=nav-link href=/now>Now</a></li><li class=nav-item><a class=nav-link href=/blog>Blog</a></li><li class=nav-item><a class=nav-link href=/projects>Projects</a></li><li class=nav-item><a class=nav-link href=/publications>Publications</a></li><li class=nav-item><a class=nav-link href=/cv>CV</a></li><li class=nav-item><a class=nav-link href=/about>About</a></li></ul></div></div></nav><div class=site-content><div class=container><div class=main-content><div class=container><div class=row><div class=col-md-1></div><div class=col-md-10><div class=mainheading><h1 class=posttitle>CONDOR</h1></div><div class=article-post><p>CONDOR (Convolutional neural network Dataflow Optimization using Reconfigurable hardware) is a project started in Novmber 2016 and that I left in May 2018, which aims at creating a scalable and easy-to-use framework to accelerate convolutional neural networks using FPGAs in the cloud.</p><h2 id=abstract>Abstract</h2><p>From the last published paper (May 2018):</p><p>&ldquo;The recent years have seen a rapid diffusion of deep learning algorithms as <em>Convolutional Neural Networks</em>, and as a consequence, an intensification of industrial and academic research focused on optimizing their implementation.
Different computing architectures have been explored, and among all of them, <strong>FPGAs</strong> seem to be a very attractive choice, since they can deliver sustained performance with high power efficiency, as CNNs can be directly mapped onto hardware, and still offer flexibility thanks to their programmability.</p><p><strong>CONDOR</strong> is an end-to-end framework to implement CNNs using a <em>dataflow</em> acceleration methodology.
The resulting spatial accelerator can be scaled in size if enough resources are available and can exploit both intra- and inter- layers parallelism.
We integrate the proposed framework with the deep learning engine <em>Caffe</em>, meaning that we are able to generate the accelerator starting from a Caffe model.
We also provide cloud integration of such framework, enabling users to synthesize and deploy the accelerator on the <em>Amazon F1 instances</em>.&rdquo;</p><h2 id=methodology>Methodology</h2><p>The framework&rsquo;s main architecture consists of three main components: <em>frontend</em>, <em>core logic</em> and <em>backend</em>.</p><p>The <em>frontend</em> component collects the network configuration (e.g. the prototxt from Caffe) and the hardware specs (e.g. board name/chip such as <em>&ldquo;xc7vx485tffg1761-2&rdquo;</em>), embeds them in a common JSON used as internal representation and forwards them to the core logic.</p><p>The <em>core logic</em> uses the internal json to create the network accelerator IP core.
Each layer is mapped to a predefined IP core template in C++ (for now Convolutional, Pooling and Fully-Connected).
The code is then synthesized using Vivado HLS, to create the layer IP core.
Finally, the layers are connected together and grouped in order to create the final accelerator IP core.</p><p>The <em>backend</em> is the component which synthesizes the accelerator IP core and integrates it with the given deployment options.
As of now, the framework supports on-premise deployment (using SDAccel) or AWS F1 (creating the AFI to be used on the online instance).</p><h2 id=media-and-contacts>Media and Contacts</h2><h4 id=papers>Papers</h4><p>IPDPS Workshop RAW 2018 - <a href=https://ieeexplore.ieee.org/document/8425400/ target=_blank>ieee</a></p><p>ISVLSI 2017 - <a href=https://ieeexplore.ieee.org/document/7987594/ target=_blank>ieee</a></p><p>IPDPS Workshop RAW 2017 - <a href=https://ieeexplore.ieee.org/document/7965030/ target=_blank>ieee</a></p><h4 id=contacts>Contacts</h4><p>Marco Bacis - <a href=mailto:marco.bacis@mail.polimi.it>marco.bacis@mail.polimi.it</a></p><p>Niccolò Raspa - <a href=mailto:niccolo.raspa@mail.polimi.it>niccolo.raspa@mail.polimi.it</a></p><p>Giuseppe Natale - <a href=mailto:giuseppe.natale@polimi.it>giuseppe.natale@polimi.it</a></p><p>Marco D. Santambrogio - <a href=mailto:marco.santambrogio@polimi.it>marco.santambrogio@polimi.it</a></p><h4 id=slides>Slides</h4><p>Below, you can find a slide deck shown while traveling to Silicon Valley (this particular talk was given at Oracle Labs):</p><div class=container><div class=row><div class=col></div><div class="col-12 col-md-8"><div style=left:0;width:100%;height:0;position:relative;padding-bottom:75.0019%;padding-top:38px><iframe src=https://www.slideshare.net/slideshow/embed_code/key/JrA0Of0JIBmbwj style=border:0;top:0;left:0;width:100%;height:100%;position:absolute allowfullscreen scrolling=no></iframe></div></div><div class=col></div></div></div></div></div><div class=col-md-1></div></div></div></div></div><footer class=footer><div class=container><div class=row><div class="col-md-6 col-sm-6 text-center text-lg-left">© Copyright Marco Bacis</div></div></div></footer></div><script src=https://code.jquery.com/jquery-3.4.1.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script><script src=https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js integrity=sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM crossorigin=anonymous></script><script src=/js/mediumish.js></script></body></html>